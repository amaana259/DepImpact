{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **DepImpact**\n",
    "\n",
    "Main repository: https://github.com/amaana259/DepImpact\n",
    "\n",
    "Source code repository: https://github.com/amaana259/depimpactsrc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Steps**\n",
    "\n",
    "- Fork repository (link provided on the Provenance Github repo).\n",
    "- Go through the directories.\n",
    "- Decompile Java File.\n",
    "- Run Java File on provided attack log.\n",
    "- Construct graphs for each run on the top ranked entry nodes.\n",
    "- Consulted results provided in excel files.\n",
    "\n",
    "**Done on the new repository.**\n",
    "\n",
    "- Cloned the source code repository (link provided by Ahmad).\n",
    "- Simulated DepImpact on the attack logs (in progress).\n",
    "- Results verification (in progress).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## **Issues Faced**:\n",
    "\n",
    "- Main repository does not have well-defined instructions on how to run the code.\n",
    "\n",
    "- The repository also does not explain the source code structure, there is only the main .jar file provided with no further instructions.\n",
    "\n",
    "- There is only one provided attack log file which is a simple password crack attack. Running the .jar file on this log file with the provided parameters, produces a set of .dot files (graphs). These graphs each belong to a specific run of the .jar file where each run implements forward causality analysis from one of the 6 top-ranked entry nodes. \n",
    "\n",
    "- To visualise the graphs, I had to install a library called graphviz and had issues installing the relevant dependencies. After successful installation, graphs produced are very large in size and not human-readable. No further results are provided after running the .jar file, only the graphs with little context and readability.\n",
    "\n",
    "- The Java file had to be decompiled for which I had to install a separate decompiler. The decompiled Java file contains further Java files which appeared to be dependencies and source code files, but I could not figure out which were which. I separated 4 directories that seemed to be the source files, but being unfamiliar with Java code, I could not decipher these code files and understand what component of the DepImpact tool is which and if they even were present in the code files. However, after looking at the source code repository, the repo also had the same 4 directories listed as comprising the source code.\n",
    "\n",
    "- Again, no clear instructions or well-definition of the code structure, since I had to find it out/guess for the main repository by myself.\n",
    "\n",
    "- A ‘results’ directory was also present that had 4 excel files, each of which applied to one of the authors’ 4 research questions. However, how these excel files were constructed was not defined; they were simply provided with no further explanations or connections to the code files provided.\n",
    "\n",
    "- Tried cloning the new repository but faced several issues:\n",
    "\n",
    "    **git clone --depth 1 https://github.com/amaana259/depimpactsrc.git\n",
    "        Cloning into 'depimpactsrc'...\n",
    "        remote: Enumerating objects: 776, done.\n",
    "        remote: Counting objects: 100% (776/776), done.\n",
    "        remote: Compressing objects: 100% (522/522), done.\n",
    "        error: RPC failed; curl 18 transfer closed with outstanding read data remaining\n",
    "        error: 325 bytes of body are still expected\n",
    "        fetch-pack: unexpected disconnect while reading sideband packet\n",
    "        fatal: early EOF\n",
    "        fatal: fetch-pack: invalid index-pack output.**\n",
    "\n",
    "    - Tried cloning the repo through Github Desktop.\n",
    "\n",
    "    - Tried cloning the repo using HTTPs through commands on terminal.\n",
    "\n",
    "    - Tried generating a SSH key-pair and cloning the repo through SSH instead of HTTPs and cloned the repository.\n",
    "\n",
    "- Large size of source code repository, datasets for attack logs are very large in size and had issues clearing required memory on my personal device."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## **How much was run?**\n",
    "\n",
    "- The provided code in the repository was fully run. The .jar file was decompiled and run on the provided attack log file. The results however were not clear as to how they were obtained and how this specific run explained their findings in the paper.\n",
    "\n",
    "- A new source code repository was provided which appears to have attack logs and pre-processing files well defined. I am currently in progress of cloning this repository and attempting to run the tool on these new logs.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## **Code Quality**\n",
    "\n",
    "- **Code structure**: Undefined in main repository, well-defined in source code repository.\n",
    "Only one .jar file provided in main repository that had to be decompiled but no further divisions for dependencies and source code files.\n",
    "\n",
    "- **Readability**: Difficult to read result graphs produced by code on main repository.\n",
    "\n",
    "- **Commenting and documentation**: None in main repository, a README.md provided in the source code repository on how to run the results.\n",
    "\n",
    "- **Optimization**: Unable to optimise .jar file in main repository due to unfamiliarity and no clear context defined on the code functionalities.\n",
    "\n",
    "- **Adherence to best practices**: No for main repository, Yes for source code repository.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## **Dataset Availability**\n",
    "\n",
    "**For Main repository**:\n",
    "\n",
    "- **Dataset used**: One attack log provided for password crack attack.\n",
    "\n",
    "- **Format**: .log and .params/config file provided.\n",
    "\n",
    "- **Availability**: Only one attack log.\n",
    "\n",
    "- **Any issues or challenges**: Paper describes 10 types of attacks, 7 of which were performed on local hosts, and 3 of which were procured from the DARPA dataset. No information on what specific attacks (and logs) were used for the findings in the paper; the paper mentions that the POI events were procured from the attacks on their own and not set POI events, neither provided to us.\n",
    "\n",
    "**For source code repository**:\n",
    "\n",
    "- **Dataset used**: Attack logs and parameter files provided.\n",
    "\n",
    "- **Format**: .log and .params/config file provided in a large tarball file.\n",
    "\n",
    "- **Availability**: Several attacks provided.\n",
    "\n",
    "- **Any issues or challenges**: Attacks provided in separate repository, not available without request. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## **Code Explanations**\n",
    "\n",
    "- **Why was a particular algorithm or model chosen?**  \n",
    "\n",
    "    No particular training model as little to none deep learning/training is involved. Algorithm-wise, a set of algorithms was applied to reduce a dependency graph to its critical component given the POI event. Implementations of these algorithms not clear in the main repository .jar file.\n",
    "\n",
    "- **How were parameters set or tuned?**\n",
    "\n",
    "    Edge merges were done with a threshold of 10s, meaning any edges that fit into this timeframe were merged, to reduce the overall size of the dependency graphs. Three types of relevances; data flow amount relevance, temporal relevance and concentration ratio were used to compute dependency weights for application of backward and forward causality analysis/algorithms.\n",
    "\n",
    "\n",
    "- **Explanation of important functions or classes.**\n",
    "\n",
    "    Not explained well in code.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## **Provided Results Evaluation**\n",
    "\n",
    "- **Evaluation of provided results:**\n",
    "\n",
    "    Result simulation to be run after compute resources (power, memory etc.) available.\n",
    "\n",
    "- **Comparison to expected results:**\n",
    "\n",
    "    N/A\n",
    "\n",
    "- **Issues or anomalies:**\n",
    "\n",
    "    N/A\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## **Conclusion**\n",
    "\n",
    "- **Main takeaways:**\n",
    "\n",
    "    Look at source code repository and test on the provided attack logs, see if results are consistent with the excel files/results provided in main repository. Also, look at how the data/statistics in the excel files are obtained, since no clear instructions are given as to how they are.\n",
    "\n",
    "- **Final thoughts or recommendations:**\n",
    "\n",
    "    Test on other attack logs obtained from public datasets. See if results are similar to the ones provided.\n",
    "\n",
    "- **Next steps for improvement:**\n",
    "\n",
    "    One idea is to merge MAGIC and DepImpact to cross-evaluate the performance of the two. The idea is to use the anomaly detection prowess of MAGIC to predict if anomalies/malicious events in attack logs are present, then see if these events when passed as a POI event, help find a critical component/attack sequence in a larger dependency graph.\n",
    "\n",
    "    Similarly, take a critical component obtained through a run of DepImpact and run the audit logs through MAGIC. See if the MAGIC is able to predict if any malicious events are present and if the POI event is detectable.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
